# LLM 最佳实践指南 (Best Practices for Model Selection)

本指南旨在帮助您根据不同的业务场景（指令解析、RAG 问答、通用闲聊）选择最合适的大模型组合。

> **更新时间**: 2026-01
> **说明**: 模型迭代迅速，建议定期关注各厂商官网的最新动态。

---

## 🎯 场景定义

在配置 `.env` 文件时，您可以为以下三个场景分别指定模型：

1.  **INSTRUCTION_LLM (指令解析)**
    *   **任务**: 理解用户意图，提取结构化参数（JSON），判断逻辑互斥。
    *   **核心能力**: 极强的指令遵循 (Instruction Following)、JSON 输出稳定性、逻辑推理。
    *   **推荐**: 性能优先，必须“听话”。

2.  **RAG_LLM (知识库问答)**
    *   **任务**: 阅读检索到的长文档片段，综合上下文回答问题。
    *   **核心能力**: 长文本处理 (Long Context)、阅读理解、减少幻觉。
    *   **推荐**: 上下文窗口大，理解能力强。

3.  **CHAT_LLM (通用闲聊)**
    *   **任务**: 处理非指令、非知识库的日常对话，维持用户粘性。
    *   **核心能力**: 响应速度快 (Latency)、情感丰富、成本低。
    *   **推荐**: 高性价比，速度优先。

---

## 🏆 厂商推荐组合

### 1. OpenAI / Azure OpenAI (行业标杆)

如果不考虑成本，OpenAI 依然是综合能力最强的选择。

| 场景 | 推荐模型 | 配置值 (`_MODEL`) | 理由 |
| :--- | :--- | :--- | :--- |
| **指令解析** | **GPT-4o** | `gpt-4o` | 目前最强的指令遵循能力，JSON 输出极其稳定。 |
| **RAG 问答** | **GPT-4o** | `gpt-4o` | 128k 上下文，阅读理解能力顶尖。 |
| **通用闲聊** | **GPT-4o-mini** | `gpt-4o-mini` | 速度极快，成本极低，且智商在线。 |

### 2. Deepseek (深度求索 - 性价比之王)

Deepseek 是目前国内最值得推荐的“全能型”选手，API 价格极具破坏力。

| 场景 | 推荐模型 | 配置值 (`_MODEL`) | 理由 |
| :--- | :--- | :--- | :--- |
| **指令解析** | **Deepseek-V3** | `deepseek-chat` | 综合能力逼近 GPT-4，指令遵循能力极强。 |
| **RAG 问答** | **Deepseek-V3** | `deepseek-chat` | 64k 上下文，擅长代码和逻辑推理，适合技术类文档。 |
| **通用闲聊** | **Deepseek-V3** | `deepseek-chat` | 价格极低（约 GPT-4o 的 1/10），完全可以用旗舰模型做闲聊。 |

> **注**: 如果涉及极其复杂的逻辑推理，可尝试 `deepseek-reasoner` (R1)。

### 3. Qwen (阿里通义千问)

阿里云百炼平台的 Qwen 系列在中文理解和工具调用方面表现优异。

| 场景 | 推荐模型 | 配置值 (`_MODEL`) | 理由 |
| :--- | :--- | :--- | :--- |
| **指令解析** | **Qwen-Max** | `qwen-max` | Qwen 3 系列的旗舰，Agent 和工具调用能力大幅增强。 |
| **RAG 问答** | **Qwen-Plus** | `qwen-plus` | 性能与成本的最佳平衡点，长文本表现稳定。 |
| **通用闲聊** | **Qwen-Turbo** | `qwen-turbo` | 速度快，免费额度通常较多，适合大量并发闲聊。 |

### 4. Zhipu AI (智谱 GLM)

智谱 GLM 系列在长文本和意图理解方面有深厚积累。

| 场景 | 推荐模型 | 配置值 (`_MODEL`) | 理由 |
| :--- | :--- | :--- | :--- |
| **指令解析** | **GLM-4-Plus** | `glm-4-plus` | 最新旗舰，指令遵循能力大幅提升。 |
| **RAG 问答** | **GLM-4-Long** | `glm-4-long` | 专为超长文本设计（支持 1M 上下文），适合海量知识库检索。 |
| **通用闲聊** | **GLM-4-Flash** | `glm-4-flash` | 免费/极低价，速度极快，完全满足日常闲聊。 |

### 5. Minimax (海螺/名之梦)

Minimax 在拟人化交互和角色扮演方面有独到优势，且近期在 Agent 能力上发力迅猛。

| 场景 | 推荐模型 | 配置值 (`_MODEL`) | 理由 |
| :--- | :--- | :--- | :--- |
| **指令解析** | **MiniMax-M2.1** | `MiniMax-M2.1` | 专为 Agent 和工具调用优化，指令执行精准。 |
| **RAG 问答** | **abab6.5s** | `abab6.5s` | 245k 上下文，处理长文档能力优秀。 |
| **通用闲聊** | **abab6.5g** | `abab6.5g` | 响应速度快，拟人化程度高，聊天更有“人味”。 |

---

## 💡 混合云策略示例 (Hybrid Strategy)

您可以结合各家之长，在 `.env` 中进行混合配置，以达到最佳的**效果-成本比**。

**示例配置：**

```ini
# 1. 用最聪明的模型做大脑（指令解析）
INSTRUCTION_LLM_PROVIDER=openai
INSTRUCTION_LLM_MODEL=gpt-4o

# 2. 用最擅长长文本的模型做阅读理解（RAG）
RAG_LLM_PROVIDER=zhipu
RAG_LLM_MODEL=glm-4-long

# 3. 用最便宜的模型做嘴巴（闲聊）
CHAT_LLM_PROVIDER=deepseek
CHAT_LLM_MODEL=deepseek-chat
```
