# AI Voice Solution (v2.1)

Product-level AI voice and semantic understanding system with Admin Dashboard, RAG, and Web Search.

## ðŸŒŸ New Features (v2.1)

*   **å¤šç§Ÿæˆ·æž¶æž„ (Multi-Tenant Architecture)**: åŸºäºŽ User ID çš„å…¨é“¾è·¯æ•°æ®éš”ç¦»ï¼Œæ”¯æŒå¤šç”¨æˆ·ç‹¬ç«‹ä½¿ç”¨ã€‚
*   **é«˜çº§ RAG å¼•æ“Ž (Advanced RAG Engine)**: 
    *   **ç´¢å¼•æ¨¡å¼**: æ”¯æŒâ€œé«˜è´¨é‡â€ï¼ˆæ·±åº¦è¯­ä¹‰ï¼‰ä¸Žâ€œç»æµŽâ€ï¼ˆå…³é”®è¯ï¼‰ä¸¤ç§æ¨¡å¼ã€‚
    *   **æ··åˆæ£€ç´¢**: ç»“åˆå‘é‡æ£€ç´¢ä¸Žå…¨æ–‡æ£€ç´¢ï¼Œæå‡å¬å›žå‡†ç¡®çŽ‡ã€‚
    *   **é‡æŽ’åº (Rerank)**: é›†æˆ Rerank æ¨¡åž‹ï¼Œæ”¯æŒè‡ªå®šä¹‰ Top-K å’Œç›¸å…³åº¦é˜ˆå€¼ã€‚
*   **æŒ‡ä»¤ç®¡ç† (Instruction Management)**: 
    *   æ”¯æŒ Function Calling å®šä¹‰çš„å¢žåˆ æ”¹æŸ¥ã€‚
    *   æ”¯æŒ Excel æ‰¹é‡å¯¼å…¥æŒ‡ä»¤é›†ã€‚
    *   å†…ç½®äº’æ–¥é€»è¾‘æ ¡éªŒã€‚
*   **æ‰¹é‡è¯„æµ‹ (Batch Evaluation)**: 
    *   æ”¯æŒä¸Šä¼  Excel æµ‹è¯•ç”¨ä¾‹ã€‚
    *   è‡ªåŠ¨è¿›è¡Œæ„å›¾è¯†åˆ«ä¸Žå…³é”®è¯åŒ¹é…æµ‹è¯•ã€‚
    *   ç”Ÿæˆå¹¶ä¸‹è½½è¯¦ç»†çš„è¯„æµ‹æŠ¥å‘Šã€‚
*   **èŠå¤©è°ƒè¯•å° (Chat Debugger)**: 
    *   æ”¯æŒå¤šä¼šè¯ç®¡ç†ï¼ˆæ–°å»º/åˆ‡æ¢/åˆ é™¤ï¼‰ã€‚
    *   å®žæ—¶å±•ç¤ºè·¯ç”±å†³ç­–ã€è€—æ—¶ (Latency) å’Œæœç´¢æºå…ƒæ•°æ®ã€‚
    *   å…¨é“¾è·¯ Trace ID è¿½è¸ªã€‚

## ðŸŒŸ New Features (v2.0)

*   **Admin Dashboard**: A Manus-style web interface for chat debugging, knowledge management, and batch evaluation.
*   **Traceability**: Full visibility into model routing, latency (TTFT), and search sources per message.
*   **Web Search**: Real-time internet access via DuckDuckGo (default), Tavily, or Serper.
*   **Batch Evaluation**: Automated testing via Excel upload with Pass/Fail metrics.
*   **Instruction Management**: Bulk import of instructions via Excel.

## ðŸ“š æœ€ä½³å®žè·µ (Best Practices)

æˆ‘ä»¬æ•´ç†äº†é’ˆå¯¹ä¸åŒåŽ‚å•†ï¼ˆOpenAI, Deepseek, Qwen, Minimax ç­‰ï¼‰åœ¨æŒ‡ä»¤è§£æžã€RAG é—®ç­”å’Œé€šç”¨é—²èŠåœºæ™¯ä¸‹çš„**æœ€ä½³æ¨¡åž‹ç»„åˆæŽ¨è**ã€‚

ðŸ‘‰ **[ç‚¹å‡»æŸ¥çœ‹ï¼šLLM é€‰åž‹æœ€ä½³å®žè·µæŒ‡å—](docs/best_practices.md)**

---

## ðŸš€ Quick Start

### 1. Backend Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Initialize Database
python app/db/init_db.py

# Start Server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8001
```

### 2. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Access the Admin Dashboard at `http://localhost:3000` (if started with port 3000) or `http://localhost:5173` (default).

## ðŸ“š Documentation

*   [System Architecture](docs/architecture_diagrams.md)
*   [Best Practices for LLM Selection](docs/best_practices.md)
*   [Technical Design (v2.0)](docs/technical_design.md)

## ðŸ›  Configuration

Copy `.env.example` to `.env` and configure:

```env
# Web Search
SEARCH_PROVIDER=duckduckgo # or tavily, serper
TAVILY_API_KEY=...

# LLM Routing
INSTRUCTION_LLM_MODEL=gpt-4.1-mini
RAG_LLM_MODEL=gpt-4.1-mini
CHAT_LLM_MODEL=gpt-4.1-mini
```

## ðŸ“Š Batch Evaluation

Prepare an Excel file with columns: `case_id`, `query`, `expected_intent`, `expected_keywords`.
Upload it in the **Batch Eval** page to get a detailed report.

## ðŸ— Architecture

![Architecture](docs/architecture.png)

### æ ¸å¿ƒè°ƒç”¨æ—¶åº (Sequence Diagram)

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API as Backend API
    participant DM as Dialogue Manager
    participant Memory as Memory Manager (Redis/PG)
    participant RAG as RAG Engine
    participant LLM as LLM Factory
    participant Provider as Model Provider

    User->>Frontend: Speak (Voice Input)
    Frontend->>API: Send Audio/Text
    API->>DM: Process Request (session_id, text)
    
    par Parallel Context Retrieval
        DM->>Memory: Get Short-term History
        Memory-->>DM: Return History List
    and
        DM->>RAG: Retrieve Relevant Docs
        RAG->>RAG: Vector Search (PG)
        RAG-->>DM: Return Context Chunks
    end
    
    DM->>DM: Construct Prompt (System + Context + History + Query)
    DM->>LLM: Create LLM Instance (Provider Config)
    LLM->>Provider: Chat Completion Request
    Provider-->>LLM: Stream/Return Response
    LLM-->>DM: Text Response
    
    par Async Save
        DM->>Memory: Save Turn (User + AI)
        Memory->>Memory: Write to Redis & PG
    end
    
    DM-->>API: Final Response Object
    API-->>Frontend: Return Text & Audio URL
    Frontend->>User: Play Audio & Show Text
```
